{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "65651ebd9af5c4c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:28:43.391695Z",
     "start_time": "2025-01-03T16:28:02.820065Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install pandas numpy matplotlib seaborn scikit-learn transformers torch",
   "id": "d5722960471bf1de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\program files\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\program files\\python311\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\program files\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (1.5.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: torch in c:\\program files\\python311\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\program files\\python311\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\program files\\python311\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\program files\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\program files\\python311\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\program files\\python311\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\program files\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\program files\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\program files\\python311\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\program files\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\igorj\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.1 MB 882.6 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 0.8/10.1 MB 987.4 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.0/10.1 MB 914.5 kB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.0/10.1 MB 914.5 kB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.3/10.1 MB 828.3 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.3/10.1 MB 828.3 kB/s eta 0:00:11\n",
      "   ------ --------------------------------- 1.6/10.1 MB 814.1 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 1.8/10.1 MB 867.5 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 2.1/10.1 MB 924.4 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.4/10.1 MB 965.5 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 2.6/10.1 MB 980.6 kB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 2.9/10.1 MB 992.6 kB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.1/10.1 MB 997.4 kB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.4/10.1 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 3.7/10.1 MB 1.0 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 3.9/10.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.2/10.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.5/10.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 4.7/10.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.0/10.1 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.5/10.1 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.8/10.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.0/10.1 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.3/10.1 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.6/10.1 MB 1.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.1/10.1 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.6/10.1 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.1/10.1 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.9/10.1 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.4 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 tokenizers-0.21.0 transformers-4.47.1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:33:47.216137Z",
     "start_time": "2025-01-03T16:33:38.803920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ],
   "id": "7648ee5ae04d0560",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Data",
   "id": "24e5f9931574a947"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:34:01.643962Z",
     "start_time": "2025-01-03T16:33:59.520146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "\n",
    "print(\"Data Shape:\", data.shape)\n",
    "print(\"Data Info:\")\n",
    "data.info()\n",
    "print(\"Data Head:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())"
   ],
   "id": "8129c039601f7245",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (57477, 9)\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57477 entries, 0 to 57476\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              57477 non-null  int64 \n",
      " 1   model_a         57477 non-null  object\n",
      " 2   model_b         57477 non-null  object\n",
      " 3   prompt          57477 non-null  object\n",
      " 4   response_a      57477 non-null  object\n",
      " 5   response_b      57477 non-null  object\n",
      " 6   winner_model_a  57477 non-null  int64 \n",
      " 7   winner_model_b  57477 non-null  int64 \n",
      " 8   winner_tie      57477 non-null  int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 3.9+ MB\n",
      "Data Head:\n",
      "       id             model_a              model_b  \\\n",
      "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
      "1   53567           koala-13b           gpt-4-0613   \n",
      "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
      "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
      "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
      "\n",
      "                                              prompt  \\\n",
      "0  [\"Is it morally right to try to have a certain...   \n",
      "1  [\"What is the difference between marriage lice...   \n",
      "2  [\"explain function calling. how would you call...   \n",
      "3  [\"How can I create a test set for a very rare ...   \n",
      "4  [\"What is the best way to travel from Tel-Aviv...   \n",
      "\n",
      "                                          response_a  \\\n",
      "0  [\"The question of whether it is morally right ...   \n",
      "1  [\"A marriage license is a legal document that ...   \n",
      "2  [\"Function calling is the process of invoking ...   \n",
      "3  [\"Creating a test set for a very rare category...   \n",
      "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
      "\n",
      "                                          response_b  winner_model_a  \\\n",
      "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
      "1  [\"A marriage license and a marriage certificat...               0   \n",
      "2  [\"Function calling is the process of invoking ...               0   \n",
      "3  [\"When building a classifier for a very rare c...               1   \n",
      "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
      "\n",
      "   winner_model_b  winner_tie  \n",
      "0               0           0  \n",
      "1               1           0  \n",
      "2               0           1  \n",
      "3               0           0  \n",
      "4               1           0  \n",
      "\n",
      "Missing Values:\n",
      "id                0\n",
      "model_a           0\n",
      "model_b           0\n",
      "prompt            0\n",
      "response_a        0\n",
      "response_b        0\n",
      "winner_model_a    0\n",
      "winner_model_b    0\n",
      "winner_tie        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:34:05.695746Z",
     "start_time": "2025-01-03T16:34:05.460628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "winner_columns = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "labels = ['Model A', 'Model B', 'Tie']\n",
    "counts = data[winner_columns].sum()\n",
    "sns.barplot(x=labels, y=counts)\n",
    "plt.title(\"Winner Distribution\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ],
   "id": "53119e4bd33965cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data processing ",
   "id": "6da9d60b17fa8dea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:34:11.414367Z",
     "start_time": "2025-01-03T16:34:11.240062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data['winner'] = data[winner_columns].idxmax(axis=1)\n",
    "data['response_combined'] = data['response_a'] + \" [SEP] \" + data['response_b']\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['winner_encoded'] = le.fit_transform(data['winner'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data[['prompt', 'response_combined']], \n",
    "    data['winner_encoded'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ],
   "id": "e530e369a3f6a970",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extraction",
   "id": "3efa2e83dd8ee1f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:34:29.135029Z",
     "start_time": "2025-01-03T16:34:13.976303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tfidf = TfidfVectorizer(max_features=20000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train['response_combined'])\n",
    "X_val_tfidf = tfidf.transform(X_val['response_combined'])"
   ],
   "id": "22368ba41197db9d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Training",
   "id": "a86cbb40a03a20a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:46:55.796373Z",
     "start_time": "2025-01-03T16:34:48.151954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_val_pred_rf = rf_model.predict_proba(X_val_tfidf)\n",
    "logloss_rf = log_loss(y_val, y_val_pred_rf)\n",
    "print(f\"Random Forest Validation Log Loss: {logloss_rf}\")\n"
   ],
   "id": "6abd95b0e86617d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Log Loss: 1.0835986694468471\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine-tuning",
   "id": "4c9c1fe63a28498d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:47:04.105975Z",
     "start_time": "2025-01-03T16:47:04.098722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, prompts, responses, targets, tokenizer, max_len):\n",
    "        self.prompts = prompts\n",
    "        self.responses = responses\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        prompt = self.prompts[item]\n",
    "        response = self.responses[item]\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text=prompt,\n",
    "            text_pair=response,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ],
   "id": "a192e2654827c49e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Parameters",
   "id": "8d8f590d0f69030a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:47:11.827602Z",
     "start_time": "2025-01-03T16:47:08.332577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PRE_TRAINED_MODEL = 'bert-base-uncased'\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL)"
   ],
   "id": "246ebb9caa1f4e0b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:51:56.305077Z",
     "start_time": "2025-01-03T16:47:15.160277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = ChatDataset(\n",
    "    prompts=X_train['prompt'].values,\n",
    "    responses=X_train['response_combined'].values,\n",
    "    targets=y_train.values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "val_dataset = ChatDataset(\n",
    "    prompts=X_val['prompt'].values,\n",
    "    responses=X_val['response_combined'].values,\n",
    "    targets=y_val.values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL, num_labels=3)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ],
   "id": "aa6faa7a24d4a382",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Optimizer",
   "id": "80c52a0aace59674"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:54:25.844795Z",
     "start_time": "2025-01-03T16:54:25.828085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Use PyTorch's AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = CrossEntropyLoss().to(device)\n"
   ],
   "id": "99c0d82f3d85237b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Trainig",
   "id": "82f7f48525607b14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:54:28.294985Z",
     "start_time": "2025-01-03T16:54:28.290078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        targets = d['targets'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        loss = loss_fn(logits, targets)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)"
   ],
   "id": "4b1274be55265e02",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation",
   "id": "a2d62bedf01517b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:54:31.215521Z",
     "start_time": "2025-01-03T16:54:31.209641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_model(model, data_loader, loss_fn, device):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d['input_ids'].to(device)\n",
    "            attention_mask = d['attention_mask'].to(device)\n",
    "            targets = d['targets'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            loss = loss_fn(logits, targets)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)"
   ],
   "id": "e84b2326bf0745ec",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Proces",
   "id": "ee9970f1194f90d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T16:58:52.712351700Z",
     "start_time": "2025-01-03T16:54:34.269217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    train_acc, train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss}, Train Accuracy: {train_acc}\")\n",
    "\n",
    "    val_acc, val_loss = eval_model(model, val_loader, loss_fn, device)\n",
    "    print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_acc}\")"
   ],
   "id": "6fe52ee0682be184",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(EPOCHS):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mEPOCHS\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m     train_acc, train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_acc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      7\u001B[0m     val_acc, val_loss \u001B[38;5;241m=\u001B[39m eval_model(model, val_loader, loss_fn, device)\n",
      "Cell \u001B[1;32mIn[14], line 11\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[1;34m(model, data_loader, loss_fn, optimizer, device)\u001B[0m\n\u001B[0;32m      8\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m d[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      9\u001B[0m targets \u001B[38;5;241m=\u001B[39m d[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtargets\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 11\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m logits \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlogits\n\u001B[0;32m     16\u001B[0m _, preds \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1665\u001B[0m, in \u001B[0;36mBertForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1657\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1658\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1659\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m   1660\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m   1661\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m   1662\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1663\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1665\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1666\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1667\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1670\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1671\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1672\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1673\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1675\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1677\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   1679\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(pooled_output)\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1142\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1135\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[0;32m   1138\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[0;32m   1139\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[0;32m   1140\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m-> 1142\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1143\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1145\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1146\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1147\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1148\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1149\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1150\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1151\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1152\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1153\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1154\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1155\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    684\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[0;32m    685\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[0;32m    686\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    692\u001B[0m         output_attentions,\n\u001B[0;32m    693\u001B[0m     )\n\u001B[0;32m    694\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 695\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    698\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    699\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    700\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    701\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    703\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    706\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:627\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    624\u001B[0m     cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    625\u001B[0m     present_key_value \u001B[38;5;241m=\u001B[39m present_key_value \u001B[38;5;241m+\u001B[39m cross_attn_present_key_value\n\u001B[1;32m--> 627\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[43mapply_chunking_to_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed_forward_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchunk_size_feed_forward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseq_len_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_output\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    630\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m outputs\n\u001B[0;32m    632\u001B[0m \u001B[38;5;66;03m# if decoder, return the attn key/values as the last output\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pytorch_utils.py:258\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;66;03m# concatenate output at same dimension\u001B[39;00m\n\u001B[0;32m    256\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[1;32m--> 258\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:640\u001B[0m, in \u001B[0;36mBertLayer.feed_forward_chunk\u001B[1;34m(self, attention_output)\u001B[0m\n\u001B[0;32m    638\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeed_forward_chunk\u001B[39m(\u001B[38;5;28mself\u001B[39m, attention_output):\n\u001B[0;32m    639\u001B[0m     intermediate_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate(attention_output)\n\u001B[1;32m--> 640\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mintermediate_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    641\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m layer_output\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:552\u001B[0m, in \u001B[0;36mBertOutput.forward\u001B[1;34m(self, hidden_states, input_tensor)\u001B[0m\n\u001B[0;32m    551\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor, input_tensor: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 552\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    553\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n\u001B[0;32m    554\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(hidden_states \u001B[38;5;241m+\u001B[39m input_tensor)\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save model",
   "id": "3f71588cf60ed137"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.save_pretrained('.data/fine_tuned_model')\n",
    "tokenizer.save_pretrained('.data/fine_tuned_model')"
   ],
   "id": "2d3292d7890d6532"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Submission",
   "id": "11589b379f271e04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "test_data['response_combined'] = test_data['response_a'] + \" [SEP] \" + test_data['response_b']\n",
    "test_tfidf = tfidf.transform(test_data['response_combined'])\n",
    "\n",
    "rf_predictions = rf_model.predict_proba(test_tfidf)\n",
    "\n",
    "def generate_transformer_predictions(test_data, model, tokenizer, max_len, device):\n",
    "    test_dataset = ChatDataset(\n",
    "        prompts=test_data['prompt'].values,\n",
    "        responses=test_data['response_combined'].values,\n",
    "        targets=[0] * len(test_data),  # Dummy targets\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for d in test_loader:\n",
    "            input_ids = d['input_ids'].to(device)\n",
    "            attention_mask = d['attention_mask'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            predictions.extend(probs.cpu().numpy())\n",
    "    return np.array(predictions)"
   ],
   "id": "57cc0483a134de5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "transformer_predictions = generate_transformer_predictions(test_data, model, tokenizer, MAX_LEN, device)\n",
    "\n",
    "final_predictions = (rf_predictions + transformer_predictions) / 2\n",
    "\n",
    "submission = pd.DataFrame(final_predictions, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "submission.insert(0, 'id', test_data['id'])"
   ],
   "id": "94c23266abe767ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file 'submission.csv' has been created.\")"
   ],
   "id": "98a59a4afa7f80ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
